# Classificador de Sinais de LIBRAS com PyTorch e Transformers

## ğŸ“– DescriÃ§Ã£o

Este projeto Ã© uma implementaÃ§Ã£o de um modelo de Deep Learning para o reconhecimento e classificaÃ§Ã£o de sinais isolados da LÃ­ngua Brasileira de Sinais (LIBRAS) a partir de vÃ­deos. Utilizando uma arquitetura *end-to-end*, o modelo analisa diretamente os pixels do vÃ­deo para realizar a classificaÃ§Ã£o, com foco em alta acurÃ¡cia e eficiÃªncia computacional.

O trabalho foi desenvolvido como parte de um artigo cientÃ­fico, comparando diferentes arquiteturas de redes neurais, como 3D-CNNs (I3D) e Video Transformers.

### âœ¨ Features

* **Alta AcurÃ¡cia:** Atinge mais de 90% de acurÃ¡cia no conjunto de teste.
* **Pipeline End-to-End:** Processa diretamente vÃ­deos brutos (RGB).
* **ValidaÃ§Ã£o Robusta:** O conjunto de teste Ã© composto por sinalizadores nÃ£o vistos durante o treinamento, garantindo a capacidade de generalizaÃ§Ã£o do modelo.
* **Reprodutibilidade:** O projeto Ã© totalmente containerizado com Docker, garantindo que qualquer pessoa possa rodar o treinamento com dois comandos.

## ğŸ› ï¸ Tecnologias Utilizadas

* Python 3.10+
* PyTorch
* FFmpeg
* Conda
* Docker
* NVIDIA CUDA

## âš™ï¸ Estrutura do Projeto

```
.
â”œâ”€â”€ dataset_splits/     # Arquivos CSV com a divisÃ£o de treino, validaÃ§Ã£o e teste
â”œâ”€â”€ training_plots/       # Pasta onde os grÃ¡ficos de treinamento sÃ£o salvos
â”œâ”€â”€ build_pytorch_model.py # Script principal para treinamento e avaliaÃ§Ã£o do modelo
â”œâ”€â”€ extract_metadata.py    # Script para extrair metadados dos vÃ­deos
â”œâ”€â”€ split_dataset.py       # Script para realizar a divisÃ£o do dataset
â”œâ”€â”€ minds_libras_metadata.csv # Metadados do dataset
â”œâ”€â”€ Dockerfile             # Receita para construir a imagem Docker do projeto
â”œâ”€â”€ environment.yml        # Lista de dependÃªncias do ambiente Conda
â””â”€â”€ README.md              # Esta documentaÃ§Ã£o
```

## ğŸš€ InstalaÃ§Ã£o e Uso

VocÃª pode rodar este projeto de duas maneiras: a forma recomendada (com Docker) ou a forma manual.

### MÃ©todo 1: Usando Docker (Recomendado)

**PrÃ©-requisitos:** [Docker](https://www.docker.com/get-started) e [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) (para suporte a GPU).

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone [https://github.com/seu-usuario/seu-repositorio.git](https://github.com/seu-usuario/seu-repositorio.git)
    cd seu-repositorio
    ```

2.  **Construa a imagem Docker:**
    ```bash
    docker build -t libras-classifier .
    ```

3.  **Execute o treinamento:**
    ```bash
    docker run --gpus all -v "$(pwd)/dataset_splits:/app/dataset_splits" -v "$(pwd)/training_plots:/app/training_plots" libras-classifier
    ```
    Os grÃ¡ficos e resultados do treinamento aparecerÃ£o na pasta `training_plots`.

### MÃ©todo 2: Manualmente com Conda

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone [https://github.com/seu-usuario/seu-repositorio.git](https://github.com/seu-usuario/seu-repositorio.git)
    cd seu-repositorio
    ```

2.  **Crie o ambiente Conda a partir do arquivo de ambiente:**
    ```bash
    conda env create -f environment.yml
    ```

3.  **Ative o ambiente:**
    ```bash
    conda activate libras_env  # Substitua 'libras_env' pelo nome do seu ambiente
    ```

4.  **Execute o script de treinamento:**
    ```bash
    python build_pytorch_model.py
    ```

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes, issues e feature requests sÃ£o bem-vindos! Sinta-se Ã  vontade para abrir uma issue para discutir melhorias.